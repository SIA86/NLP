{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPdojVD+PVlGylHLvbqw2n4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWZhfbr1x9Rl"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install transformers[sentencepiece]\n",
        "!pip install xformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, re\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "M3iOztGHyDXA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_PATH = '/content/test_ololo (2).xlsx' #исходник с темами и описанием\n",
        "OUTPUT_PATH = '/content/result.csv' #файл с сортированными темами\n",
        "THEME_NAMES_PATH = '/content/themes.xlsx' #файл с темами (категориями)\n",
        "SUMMARY = '/content/summary.csv' #файл подсчет количества тем\n",
        "\n",
        "def cleaning_up(raw_text):\n",
        "    regex1 = r\"{[a-zA-z0-9.,!|;:*#]+}|![a-zA-z0-9.*,!|;:#]+!|\\n|\\xa0\"\n",
        "    regex2 =r\"[Дд]обр.{1,3}\\s.{1,6}[!.\\s]|[зЗ]драв.{1,8}[!.\\s]|[;]\"\n",
        "    subst = ''\n",
        "    result = re.sub(regex1, subst, raw_text, 0, re.MULTILINE)\n",
        "    result = re.sub(regex2, subst, result, 0, re.MULTILINE)\n",
        "    result = result.split('УВЕДОМЛЕНИЕ О КОНФИДЕНЦИАЛЬНОСТИ')[0].strip()\n",
        "\n",
        "    return result\n",
        "\n",
        "def load_and_process():\n",
        "    #Объединяем столбцы в одни текст\n",
        "    print('Обработка исходных данных')\n",
        "    data = pd.read_excel(SOURCE_PATH, header=0)\n",
        "    data = data.iloc[:,:3]\n",
        "    data = data.fillna('')\n",
        "    data['Описание'] = data['Описание'].apply(lambda row: cleaning_up(row)) #вычищаем весь мусор\n",
        "\n",
        "    data['Разделитель'] = '. '\n",
        "    data['Тема_с_описанием'] = data['Тема'] + data['Разделитель'] + data['Описание'] #объединяем тему с описанием\n",
        "    data = data[['Тема', 'Тема_с_описанием']]\n",
        "\n",
        "    return data\n",
        "\n"
      ],
      "metadata": {
        "id": "2LMip8aZyFuy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Подгрузка предобученной модели ИИ (https://huggingface.co/models?pipeline_tag=zero-shot-classification&language=ru&sort=trending)\n",
        "print('Загрузка предобученной нейронной сети')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased', truncation=True, truncation_side='right')\n",
        "classifier = pipeline(\"text-classification\", model='SIA86/bert-cased-text_class', tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "nRxoX0Wnz5Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Загрузка и очистка входных данных')\n",
        "preprocessed_data = load_and_process()\n",
        "#preprocessed_data"
      ],
      "metadata": {
        "id": "nCExf4Pk0qxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Чтение данных и запись тем в новый файл. Если чтение прервется - просто перезапустить скрипт. Чтения начнется с того места, где остановились\n",
        "print('Проверка наличия ранее созданного файла для вывода данных')\n",
        "if not os.path.isfile(OUTPUT_PATH): #если файл не был ранее создан\n",
        "    print('Файл не найден')\n",
        "    with open(OUTPUT_PATH, 'w', encoding=\"utf-8\") as fw:\n",
        "        fw.write('Тема;Тема_с_описанием;Категория;\\n') #создаем файл и записываем туда заголовок\n",
        "        print(f'Создан файл для вывовда данных: {OUTPUT_PATH}')\n",
        "else:\n",
        "    print(f'Найден ранее созданный файл {OUTPUT_PATH}')\n",
        "\n",
        "with open(OUTPUT_PATH, 'r', encoding=\"utf-8\") as fr: #определяем сколько строк уже проанализировано ранее\n",
        "    lines = fr.readlines()\n",
        "    total_length = len(lines)-1 #всего строк в файле за вычетом заголовка\n",
        "    print(f'Всего записей в файле для вывода данных: {total_length}')\n",
        "\n",
        "cathegory = pd.read_excel(THEME_NAMES_PATH, header=None).to_dict()[0]"
      ],
      "metadata": {
        "id": "3dBmlw2g0CKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in preprocessed_data[total_length:].rolling(1): #двигаемся по строкам начинная с места остановки\n",
        "  print(f'ИИ анализирует {row.index[0]} строку из таблицы')\n",
        "  result = classifier(row['Тема_с_описанием'].iloc[0]) #отправляем строку к ИИ\n",
        "  indx = int(result[0]['label'].removeprefix('LABEL_'))\n",
        "\n",
        "  with open(OUTPUT_PATH, 'a', encoding=\"utf-8\") as fw:\n",
        "    fw.write(f\"{row['Тема'].iloc[0]};{row['Тема_с_описанием'].iloc[0]};{cathegory[indx]}\")\n",
        "    fw.write('\\n')\n",
        "\n",
        "print('Анализ исходных данных завершен.')\n",
        "\n"
      ],
      "metadata": {
        "id": "I_shCEVVzoM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#сохранение в excel формат\n",
        "df = pd.read_csv(OUTPUT_PATH, sep=';')\n",
        "df.to_excel(OUTPUT_PATH.removesuffix('csv')+'xlsx', header=False)"
      ],
      "metadata": {
        "id": "KDpg18kWNCxI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Считаем количество тем и выводим результат в отдельный файл\n",
        "print('Идет подсчет совпадений по каждой теме')\n",
        "themes_df = pd.read_csv(OUTPUT_PATH, sep=';')\n",
        "themes_df = themes_df['Категория']\n",
        "\n",
        "df = pd.DataFrame(np.zeros(shape=(1,len(cathegory))), columns=list(cathegory.values()))\n",
        "\n",
        "for cathegory in list(cathegory.values()):\n",
        "    try:\n",
        "        df[cathegory] = themes_df.value_counts()[cathegory]\n",
        "    except KeyError:\n",
        "        pass\n",
        "df= df.T\n",
        "df.index = df.index.rename('Тема')\n",
        "df = df.rename(columns={0:'Количество'})\n",
        "df.to_csv(SUMMARY) #запись в CSV файл\n",
        "print(f'Статистика по темам выведена в файл {SUMMARY}')\n"
      ],
      "metadata": {
        "id": "YsRQehyW1Rvj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}